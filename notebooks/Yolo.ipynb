{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo (You Only Look Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import uuid\n",
    "import shutil\n",
    "import logging\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow, Project\n",
    "from typing import Any, Literal, Pattern\n",
    "from roboflow.core.dataset import Dataset\n",
    "from roboflow.core.version import Version\n",
    "from supervision.detection.core import Detections\n",
    "from torch.cuda import is_available, empty_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class DirectoryUtil:\n",
    "    \"\"\"Utility class for handling directories.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def directory_exists(path: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the specified directory exists.\n",
    "        \n",
    "        Args:\n",
    "            path (str): The directory path.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if the directory exists, False otherwise.\n",
    "        \"\"\"\n",
    "        return os.path.isdir(s=path)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_directory(path: str) -> None:\n",
    "        \"\"\"\n",
    "        Creates a directory at the specified path.\n",
    "        If the directory already exists, no exception is raised.\n",
    "        \n",
    "        Args:\n",
    "            path (str): The directory path.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            os.makedirs(name=path, exist_ok=True)\n",
    "            logging.info(msg=f\"Directory created: {path}\")\n",
    "        except Exception as e:\n",
    "            logging.info(msg=f\"Error creating directory {path}: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def ensure_directory(path: str) -> str:\n",
    "        \"\"\"\n",
    "        Ensures that the directory exists. If it does not, the directory is created.\n",
    "        \n",
    "        Args:\n",
    "            path (str): The directory path.\n",
    "\n",
    "        Return:\n",
    "            str: Directory path.\n",
    "        \"\"\"\n",
    "        if not DirectoryUtil.directory_exists(path):\n",
    "            DirectoryUtil.create_directory(path)\n",
    "            return path\n",
    "        else:\n",
    "            logging.info(msg=f\"Directory already exists: {path}\")\n",
    "            return path\n",
    "\n",
    "    @staticmethod\n",
    "    def find_downloaded_dataset(datasets_path: str, project_id: str, version_number: int) -> str:\n",
    "        # logging.info(f\"Directories in '{datasets_path}': {os.listdir(datasets_path)}\")\n",
    "\n",
    "        expected_name = f\"{project_id}-{version_number}\"\n",
    "        pattern: Pattern[str] = re.compile(re.escape(pattern=expected_name), re.IGNORECASE)\n",
    "\n",
    "        for folder in os.listdir(path=datasets_path):\n",
    "            folder_path: str = os.path.join(datasets_path, folder)\n",
    "\n",
    "            # logging.info(f\"Comparing: '{folder}' vs '{expected_name}'\")\n",
    "\n",
    "            if os.path.isdir(s=folder_path) and pattern.search(string=folder):\n",
    "                return folder_path \n",
    "\n",
    "        logging.error(f\"Dataset not found for: '{project_id}-{version_number}' in '{datasets_path}'.\")\n",
    "        raise FileNotFoundError(f\"Dataset not found for: '{project_id}-{version_number}' in '{datasets_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, model: YOLO, data: str, epochs: int, device: str, batch: int, imgsz: int, optimizer: str) -> None:\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.batch = batch\n",
    "        self.imgsz = imgsz\n",
    "        self.optimizer = optimizer\n",
    "        self.lr0 = 0.001\n",
    "        self.patience = None\n",
    "        self.weight_decay = None\n",
    "        self.momentum = None\n",
    "        self.warmup_epochs = None\n",
    "        self.mixup = None\n",
    "        self.mosaic = None\n",
    "        self.copy_paste = None\n",
    "        \n",
    "    def train(self) -> None:\n",
    "        all_train_params: dict[str, str | int | float | None] = { \n",
    "            \"data\": self.data,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"device\": self.device,\n",
    "            \"batch\": self.batch,\n",
    "            \"patience\": self.patience,\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr0\": self.lr0,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"momentum\": self.momentum,\n",
    "            \"warmup_epochs\": self.warmup_epochs,\n",
    "            \"mixup\": self.mixup,\n",
    "            \"mosaic\": self.mosaic,\n",
    "            \"copy_paste\": self.copy_paste,\n",
    "        }\n",
    "\n",
    "        train_params: dict[str, str | int | float]  = {key: value for key, value in all_train_params.items() if value is not None}\n",
    "\n",
    "        logging.info(msg=f\"Training model with parameters: {train_params}\")\n",
    "        self.model.train(**train_params)\n",
    "\n",
    "\n",
    "class RoboflowDataset:\n",
    "    def __init__(self, \n",
    "                datasets_path: str, \n",
    "                api_key: str, \n",
    "                the_workspace: str, \n",
    "                project_id: str, \n",
    "                version_number: int,\n",
    "                model_format: str) -> None:\n",
    "\n",
    "        self.datasets_path = datasets_path\n",
    "        self.api_key = api_key\n",
    "        self.the_workspace = the_workspace\n",
    "        self.project_id = project_id\n",
    "        self.version_number = version_number\n",
    "        self.model_format = model_format\n",
    "        self.dataset_path = None\n",
    "\n",
    "\n",
    "    def download_dataset(self) -> None:\n",
    "        try:\n",
    "            os.chdir(path=self.datasets_path)\n",
    "            rf: Roboflow = Roboflow(api_key=self.api_key)\n",
    "            project: Project = rf.workspace(the_workspace=self.the_workspace).project(project_id=self.project_id)\n",
    "            version: Version = project.version(version_number=self.version_number)\n",
    "            dataset: Dataset = version.download(model_format=self.model_format)\n",
    "        except:\n",
    "            logging.error(msg=f\"Something went wrong downloading the dataset\")\n",
    "            ValueError('Something went wrong downloading the dataset.')\n",
    "    \n",
    "    def find_dataset_path(self) -> str | None:\n",
    "        try:\n",
    "            dataset_path: str = DirectoryUtil.find_downloaded_dataset(datasets_path=self.datasets_path,\n",
    "                                                                    project_id=self.project_id,\n",
    "                                                                    version_number=self.version_number)\n",
    "            logging.info(msg=f\"Dataset is: {dataset_path}\")\n",
    "            self.dataset_path = dataset_path\n",
    "            return dataset_path\n",
    "        except:\n",
    "            logging.error(msg=f\"Something went wrong finding the dataset\")\n",
    "            ValueError('Something went wrong finding the dataset.')\n",
    "    \n",
    "    def prepare_dataset_datayml(self) -> None:\n",
    "        if self.dataset_path is None:\n",
    "            logging.error(msg=f\"Dataset path is not set. Run find_dataset_path() first.\")\n",
    "            raise ValueError(\"Dataset path is not set. Run find_dataset_path() first.\")\n",
    "\n",
    "        dataset_datayml_path: str = os.path.join(self.dataset_path, 'data.yaml')\n",
    "        # logging.info(msg=f\"dataset_datayml_path {dataset_datayml_path}\")\n",
    "\n",
    "        with open(file=dataset_datayml_path, mode='r') as file:\n",
    "            datayml_file: list[str] = file.readlines()\n",
    "\n",
    "        # logging.info(msg=f\"datayml_file {datayml_file} \")\n",
    "\n",
    "        pattern: Pattern[str] = re.compile(r\"https?://[^\\s]+\") \n",
    "\n",
    "        if(any(pattern.search(line) for line in datayml_file)):\n",
    "\n",
    "            logging.info(msg=f\"Dataset is not prepared. Preparing it...\")\n",
    "            datayml_file = datayml_file[:-4]\n",
    "            logging.info(msg=f\"Removed unneccesary content.\")\n",
    "\n",
    "            datayml_file = [line.replace(\"../train/images\", f\"{self.dataset_path}/train/images\") for line in datayml_file]\n",
    "            datayml_file = [line.replace(\"../valid/images\", f\"{self.dataset_path}/valid/images\") for line in datayml_file]\n",
    "            datayml_file = [line.replace(\"../test/images\", f\"{self.dataset_path}/test/images\") for line in datayml_file]\n",
    "\n",
    "            logging.info(msg=f\"Added correct train, valid and test images path.\")\n",
    "\n",
    "            with open(file=dataset_datayml_path,mode= 'w') as f:\n",
    "                f.writelines(datayml_file)\n",
    "\n",
    "            logging.info(msg=f\"Saved prepared file.\")\n",
    "        \n",
    "        logging.info(msg=f\"Dataset is ready to use for training.\")\n",
    "\n",
    "    def get_datayml_path(self) -> str:\n",
    "        if self.dataset_path is None:\n",
    "            logging.error(msg=f\"Dataset path is not set. Run find_dataset_path() and prepare_dataset_datayml() first.\")\n",
    "            raise ValueError(\"Dataset path is not set. Run find_dataset_path() and prepare_dataset_datayml() first.\")\n",
    "\n",
    "        return os.path.join(self.dataset_path, 'data.yaml') \n",
    "\n",
    "class Yolo:\n",
    "    def __init__(self,\n",
    "                models_dir: str,\n",
    "                yolo_model: str = \"yolov12l.pt\",\n",
    "                min_code_prediction_threshold: int = 3,\n",
    "                min_diagram_prediction_threshold: int = 3) -> None:\n",
    "\n",
    "        self.models_dir = models_dir\n",
    "        self.yolo_model = yolo_model\n",
    "\n",
    "        self.yolo_path: str = os.path.join(models_dir, \"yolov12\")\n",
    "        if os.path.isdir(s=self.yolo_path):\n",
    "            logging.info(msg=\"Yolo was found. Initializing.\")\n",
    "        else:\n",
    "            logging.info(msg=\"Yolo was not found, dowloading it...\")\n",
    "            os.chdir(path=self.models_dir)\n",
    "            repo_url: str = f\"https://github.com/sunsmarterjie/yolov12\"\n",
    "\n",
    "            try:\n",
    "                logging.info(msg=\"Downloading...\")\n",
    "                subprocess.run([\"git\", \"clone\", repo_url, self.yolo_path], check=True)\n",
    "                logging.info(msg=\"Downloaded completed...\")\n",
    "            except subprocess.CalledProcessError:\n",
    "                logging.error(msg=\"Cloud not download yolov12 from git. Check if git is installed.\")\n",
    "                RuntimeError(\"Cloud not download yolov12 from git. Check if git is installed.\")\n",
    "            \n",
    "            commands: list[list[str]] = [\n",
    "                [\"pip\", \"install\", \"roboflow\", \"supervision\", \"flash-attn\", \"--upgrade\", \"-q\"],\n",
    "                [\"pip\", \"install\", \"-r\", \"requirements.txt\"],\n",
    "                [\"pip\", \"install\", \"-e\", \".\"],\n",
    "                [\"pip\", \"install\", \"--upgrade\", \"flash-attn\"],\n",
    "                [\"wget\", f\"https://github.com/sunsmarterjie/yolov12/releases/download/v1.0/{yolo_model}\"]\n",
    "            ]\n",
    "\n",
    "            os.chdir(path=self.yolo_path)\n",
    "            for command in commands:\n",
    "                try:\n",
    "                    logging.info(msg=f\"Executing {' '.join(command)}\")\n",
    "                    subprocess.run(command, check=True)\n",
    "                    logging.info(msg=\"Command executed successfully\")\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    logging.info(msg=f\"Error while executing {command}. Details: {e}\")\n",
    "\n",
    "        self.device: Literal['cuda', 'cpu'] = \"cuda\" if is_available() else \"cpu\"\n",
    "        if self.device == 'cuda':\n",
    "            logging.info(msg=\"GPU detected. Using it.\")\n",
    "        elif self.device == 'cpu':\n",
    "            logging.info(msg=\"GPU not detected. Swichting to CPU.\")\n",
    "        \n",
    "        path_to_model: str = os.path.join(self.yolo_path, yolo_model)\n",
    "        if not os.path.isfile(path=path_to_model):\n",
    "            logging.error(msg=f\"Model not found at: {path_to_model}\")\n",
    "            raise FileNotFoundError(f\"Model not found at: {path_to_model}\")\n",
    "\n",
    "        self.model = YOLO(model=path_to_model).to(self.device)\n",
    "        self.code_model = None\n",
    "        self.diagram_model = None\n",
    "        self.min_code_prediction_threshold = min_code_prediction_threshold\n",
    "        self.min_diagram_prediction_threshold = min_diagram_prediction_threshold\n",
    "        self.valid_subjects = {\"code\", \"diagram\"}\n",
    "        self.valid_images_extensions = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
    "\n",
    "    def set_code_model(self, path: str) -> None:\n",
    "        self.code_model = YOLO(model=path).to(self.device)\n",
    "        logging.info(msg=f\"Code model set to: {path}\")\n",
    "\n",
    "    def set_diagram_model(self, path: str) -> None:\n",
    "        self.diagram_model = YOLO(model=path).to(self.device)\n",
    "        logging.info(msg=f\"Diagram model set to: {path}\")\n",
    "    \n",
    "    def clear_cache(self) -> None:\n",
    "        empty_cache()\n",
    "        logging.info(msg=\"GPU cache has been cleared.\")\n",
    "\n",
    "    def is_subject_valid(self, subject: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the given subject extension is valid.\n",
    "\n",
    "        Args:\n",
    "            subject (str): The subject (e.g., \".code\").\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the subject is valid, False otherwise.\n",
    "        \"\"\"\n",
    "        return subject.lower() in self.valid_subjects\n",
    "\n",
    "    # def set_code_model(self, path: str) -> None:\n",
    "\n",
    "    def is_image_extension_valid(self, image_extension: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the given image extension is valid.\n",
    "\n",
    "        Args:\n",
    "            image_extension (str): The image extension (e.g., \".png\").\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the extension is valid, False otherwise.\n",
    "        \"\"\"\n",
    "        return image_extension.lower() in self.valid_images_extensions\n",
    "    \n",
    "    def format_detections_to_predictions(self, detections) -> dict[str, list[Any]]:\n",
    "        formatted_predictions: list[Any] = []\n",
    "\n",
    "        for i, (xyxy, conf, cls) in enumerate(zip(detections.xyxy, detections.confidence, detections.class_id)):\n",
    "            x_min, y_min, x_max, y_max = xyxy\n",
    "            \n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            x_center = x_min + width / 2\n",
    "            y_center = y_min + height / 2\n",
    "\n",
    "            detection_id: str = str(uuid.uuid4())\n",
    "\n",
    "            formatted_predictions.append({\n",
    "                \"x\": round(number=float(x_center),ndigits=2),\n",
    "                \"y\": round(number=float(y_center), ndigits=2),\n",
    "                \"width\": round(number=float(width), ndigits=2),\n",
    "                \"height\": round(number=float(height), ndigits=2),\n",
    "                \"confidence\": round(number=float(conf),ndigits=3),\n",
    "                \"class\": \"code_snippet\",\n",
    "                \"class_id\": int(cls),\n",
    "                \"detection_id\": detection_id\n",
    "            })\n",
    "\n",
    "        return {\"predictions\": formatted_predictions}\n",
    "\n",
    "    def save_filtered_images(self, where_to_save: Path, filtered_images_path: list[Path]) -> None:\n",
    "        for image_path in filtered_images_path:\n",
    "            shutil.copy(src=image_path, dst=where_to_save)\n",
    "            logging.info(msg=f\"Image: '{image_path.name}' has been copied to '{where_to_save}'.\")\n",
    "\n",
    "    def filter_images_with_code(self, images_path: Path) -> list[Path]:\n",
    "        if self.code_model is None:\n",
    "            raise ValueError(\"Code Model is not set. Run train_model(subject='code') or set_code_model(path='path/to/model') first.\")\n",
    "\n",
    "        valid_code_images_path: list[Path] = []\n",
    "\n",
    "        all_images_paths: list[Path] = [file for file in images_path.iterdir() if self.is_image_extension_valid(image_extension=file.suffix)]\n",
    "\n",
    "        for image_path in all_images_paths:\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                logging.error(msg=f\"Image: '{image_path.name}' could not be loaded. Skipping to the next image.\")\n",
    "                continue\n",
    "                \n",
    "            raw_code_detection_results = self.code_model(source=image, verbose=False)[0]\n",
    "            code_detection_resutls: Detections = Detections.from_ultralytics(ultralytics_results=raw_code_detection_results).with_nms()\n",
    "            code_predictions: dict[str, list[Any]] = self.format_detections_to_predictions(detections=code_detection_resutls)\n",
    "\n",
    "            if len(code_predictions[\"predictions\"]) > self.min_code_prediction_threshold:\n",
    "                valid_code_images_path.append(image_path)\n",
    "        \n",
    "        save_images_in: Path = images_path.parent / \"detects_prevalid_scenes\"\n",
    "        DirectoryUtil.ensure_directory(path=str(save_images_in))\n",
    "\n",
    "        self.save_filtered_images(where_to_save=save_images_in, filtered_images_path=valid_code_images_path)\n",
    "        logging.info(msg=f\"Filtered images have been saved in: {save_images_in}\")\n",
    "        return valid_code_images_path\n",
    "\n",
    "    def filter_iamges_with_diagrams(self, images_path: Path) -> list[Path]:\n",
    "        if self.diagram_model is None:\n",
    "            raise ValueError(\"Diagram Model is not set. Run train_model(subject='code') or set_diagram_model(path='path/to/model') first.\")\n",
    "\n",
    "        valid_diagram_images_path: list[Path] = []\n",
    "\n",
    "        all_images_paths: list[Path] = [file for file in images_path.iterdir() if self.is_image_extension_valid(image_extension=file.suffix)]\n",
    "\n",
    "        for image_path in all_images_paths:\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                logging.error(msg=f\"Image: '{image_path.name}' could not be loaded. Skipping to the next image.\")\n",
    "                continue\n",
    "                \n",
    "            raw_diagram_detection_results = self.diagram_model(source=image, verbose=False)[0]\n",
    "            diagram_detection_resutls: Detections  = Detections.from_ultralytics(ultralytics_results=raw_diagram_detection_results).with_nms()\n",
    "            diagram_predictions: dict[str, list[Any]] = self.format_detections_to_predictions(detections=diagram_detection_resutls)\n",
    "\n",
    "            if len(diagram_predictions[\"predictions\"]) > self.min_diagram_prediction_threshold:\n",
    "                valid_diagram_images_path.append(image_path)\n",
    "\n",
    "        return valid_diagram_images_path    \n",
    "    \n",
    "    def filter_images_with(self, subject: str, images_path: Path) -> None:\n",
    "        if not self.is_subject_valid(subject):\n",
    "            logging.error(msg=f\"Subject is not valid. Only 'code' and 'diagram' are valid.\")\n",
    "            raise ValueError(\"Subject is not valid. Only 'code' and 'diagram' are valid.\")\n",
    "\n",
    "        match subject:\n",
    "            case \"code\":\n",
    "                self.filter_images_with_code(images_path)\n",
    "            case \"diagram\":\n",
    "                self.filter_iamges_with_diagrams(images_path)\n",
    "\n",
    "    def train_code_model_with_dataset(self, roboflowDataset: RoboflowDataset) -> None:\n",
    "        roboflowDataset.download_dataset()\n",
    "        roboflowDataset.find_dataset_path()\n",
    "        if(roboflowDataset.dataset_path is None):\n",
    "            logging.error(msg=\"Dataset path is not set. Run find_dataset_path() or check your params.\")\n",
    "            raise ValueError(\"Dataset path is not set. Run find_dataset_path() or check your params.\")\n",
    "\n",
    "        roboflowDataset.prepare_dataset_datayml()\n",
    "\n",
    "        train_params: dict[str, Any] = {\n",
    "            \"epochs\": 300,\n",
    "            \"device\": self.device,\n",
    "            \"batch\": 14,\n",
    "            \"imgsz\": 640,\n",
    "            \"optimizer\": \"AdamW\"\n",
    "        }\n",
    "\n",
    "        os.chdir(path=self.yolo_path)\n",
    "        model: Model = Model(model=self.model, data=roboflowDataset.get_datayml_path(), **train_params)\n",
    "        model.train()\n",
    "\n",
    "    # def train_model_with_and_dataset(self, subject: str) -> None:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR: str = '/teamspace/studios/this_studio/models'\n",
    "DATASET_DIR: str = '/teamspace/studios/this_studio/datasets'\n",
    "IMAGES_DIR: str = '/teamspace/studios/this_studio/detects_scenes'\n",
    "VALID_IAMGES_DIR = '/teamspace/studios/this_studio/valid_detects_scenes'\n",
    "API_KEY: str = os.environ[\"ROBOFLOW_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 02:25:11,871 - INFO - Directory already exists: /teamspace/studios/this_studio/models\n",
      "2025-03-21 02:25:11,873 - INFO - Yolo was found. Initializing.\n",
      "2025-03-21 02:25:11,902 - INFO - GPU detected. Using it.\n"
     ]
    }
   ],
   "source": [
    "models_dir: str = DirectoryUtil.ensure_directory(path=MODELS_DIR)\n",
    "\n",
    "yolov12: Yolo = Yolo(models_dir=models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets_path = DirectoryUtil.ensure_directory(path=DATASET_DIR)\n",
    "# api_key: str = API_KEY\n",
    "# the_workspace: str = 'bot-interactivo-tesis'\n",
    "# project_id: str = 'code-snippet-detection'\n",
    "# version_number: int = 22\n",
    "# model_format: str = 'yolov12'\n",
    "\n",
    "# codeRoboflowDataset: RoboflowDataset = RoboflowDataset(datasets_path=datasets_path,\n",
    "#                                                         api_key=api_key,\n",
    "#                                                         the_workspace=the_workspace,\n",
    "#                                                         project_id=project_id,\n",
    "#                                                         version_number=version_number,\n",
    "#                                                         model_format=model_format)\n",
    "\n",
    "# yolov12.clear_cache()\n",
    "\n",
    "# yolov12.train_code_model_with_dataset(roboflowDataset=codeRoboflowDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 02:25:12,472 - INFO - Directory already exists: /teamspace/studios/this_studio/detects_scenes\n"
     ]
    }
   ],
   "source": [
    "images_dir: str = DirectoryUtil.ensure_directory(path=IMAGES_DIR)\n",
    "subject: str = \"code\"\n",
    "images_path: Path = Path(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 02:25:12,727 - INFO - Code model set to: /teamspace/studios/this_studio/models/yolov12/runs/detect/train7/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "yolov12.set_code_model(path=\"/teamspace/studios/this_studio/models/yolov12/runs/detect/train7/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 02:25:20,568 - INFO - Directory created: /teamspace/studios/this_studio/detects_prevalid_scenes\n",
      "2025-03-21 02:25:20,571 - INFO - Image: 'test_01-Scene-003-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,573 - INFO - Image: 'test_01-Scene-003-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,574 - INFO - Image: 'test_01-Scene-003-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,576 - INFO - Image: 'test_01-Scene-005-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,577 - INFO - Image: 'test_01-Scene-005-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,579 - INFO - Image: 'test_01-Scene-005-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,581 - INFO - Image: 'test_01-Scene-007-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,583 - INFO - Image: 'test_01-Scene-007-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,584 - INFO - Image: 'test_01-Scene-007-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,586 - INFO - Image: 'test_01-Scene-009-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,588 - INFO - Image: 'test_01-Scene-009-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,589 - INFO - Image: 'test_01-Scene-009-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,591 - INFO - Image: 'test_01-Scene-011-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,592 - INFO - Image: 'test_01-Scene-011-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,594 - INFO - Image: 'test_01-Scene-011-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,595 - INFO - Image: 'test_01-Scene-012-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,597 - INFO - Image: 'test_01-Scene-012-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,598 - INFO - Image: 'test_01-Scene-012-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,600 - INFO - Image: 'test_01-Scene-013-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,601 - INFO - Image: 'test_01-Scene-013-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,603 - INFO - Image: 'test_01-Scene-013-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,604 - INFO - Image: 'test_01-Scene-014-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,606 - INFO - Image: 'test_01-Scene-014-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,607 - INFO - Image: 'test_01-Scene-014-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,609 - INFO - Image: 'test_01-Scene-015-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,611 - INFO - Image: 'test_01-Scene-015-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,613 - INFO - Image: 'test_01-Scene-015-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,614 - INFO - Image: 'test_01-Scene-017-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,616 - INFO - Image: 'test_01-Scene-017-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,617 - INFO - Image: 'test_01-Scene-017-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,619 - INFO - Image: 'test_01-Scene-018-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,620 - INFO - Image: 'test_01-Scene-019-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,621 - INFO - Image: 'test_01-Scene-019-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,623 - INFO - Image: 'test_01-Scene-020-03.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,624 - INFO - Image: 'test_01-Scene-021-01.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,625 - INFO - Image: 'test_01-Scene-021-02.png' has been copied to '/teamspace/studios/this_studio/detects_prevalid_scenes'.\n",
      "2025-03-21 02:25:20,626 - INFO - Filtered images have been saved in: /teamspace/studios/this_studio/detects_prevalid_scenes\n"
     ]
    }
   ],
   "source": [
    "yolov12.filter_images_with(subject=subject, images_path=images_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
