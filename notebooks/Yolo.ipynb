{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo (You Only Look Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import uuid\n",
    "import shutil\n",
    "import logging\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Image\n",
    "from roboflow import Roboflow, Project\n",
    "from typing import Any, Literal, Pattern, Tuple\n",
    "from roboflow.core.dataset import Dataset\n",
    "from roboflow.core.version import Version\n",
    "from supervision.detection.core import Detections\n",
    "from torch.cuda import is_available, empty_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class DirectoryUtil:\n",
    "    \"\"\"Utility class for handling directories.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def directory_exists(path: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the specified directory exists.\n",
    "        \n",
    "        Args:\n",
    "            path (str): The directory path.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if the directory exists, False otherwise.\n",
    "        \"\"\"\n",
    "        return os.path.isdir(s=path)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_directory(path: str) -> None:\n",
    "        \"\"\"\n",
    "        Creates a directory at the specified path.\n",
    "        If the directory already exists, no exception is raised.\n",
    "        \n",
    "        Args:\n",
    "            path (str): The directory path.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            os.makedirs(name=path, exist_ok=True)\n",
    "            logging.info(msg=f\"Directory created: {path}\")\n",
    "        except Exception as e:\n",
    "            logging.info(msg=f\"Error creating directory {path}: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def ensure_directory(path: str) -> str:\n",
    "        \"\"\"\n",
    "        Ensures that the directory exists. If it does not, the directory is created.\n",
    "        \n",
    "        Args:\n",
    "            path (str): The directory path.\n",
    "\n",
    "        Return:\n",
    "            str: Directory path.\n",
    "        \"\"\"\n",
    "        if not DirectoryUtil.directory_exists(path):\n",
    "            DirectoryUtil.create_directory(path)\n",
    "            return path\n",
    "        else:\n",
    "            logging.info(msg=f\"Directory already exists: {path}\")\n",
    "            return path\n",
    "\n",
    "    @staticmethod\n",
    "    def find_downloaded_dataset(datasets_path: str, project_id: str, version_number: int) -> str:\n",
    "        # logging.info(f\"Directories in '{datasets_path}': {os.listdir(datasets_path)}\")\n",
    "\n",
    "        expected_name: str = f\"{project_id}-{version_number}\"\n",
    "        pattern: Pattern[str] = re.compile(re.escape(pattern=expected_name), re.IGNORECASE)\n",
    "\n",
    "        for folder in os.listdir(path=datasets_path):\n",
    "            folder_path: str = os.path.join(datasets_path, folder)\n",
    "\n",
    "            # logging.info(f\"Comparing: '{folder}' vs '{expected_name}'\")\n",
    "\n",
    "            if os.path.isdir(s=folder_path) and pattern.search(string=folder):\n",
    "                return folder_path \n",
    "\n",
    "        logging.error(msg=f\"Dataset not found for: '{project_id}-{version_number}' in '{datasets_path}'.\")\n",
    "        raise FileNotFoundError(f\"Dataset not found for: '{project_id}-{version_number}' in '{datasets_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, model: YOLO, data: str, epochs: int, device: str, batch: int, imgsz: int, optimizer: str) -> None:\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.batch = batch\n",
    "        self.imgsz = imgsz\n",
    "        self.optimizer = optimizer\n",
    "        self.lr0 = 0.001\n",
    "        self.patience = None\n",
    "        self.weight_decay = None\n",
    "        self.momentum = None\n",
    "        self.warmup_epochs = None\n",
    "        self.mixup = None\n",
    "        self.mosaic = None\n",
    "        self.copy_paste = None\n",
    "        \n",
    "    def train(self) -> None:\n",
    "\n",
    "        datayml_path = f\"{self.data}/data.yaml\"\n",
    "\n",
    "        all_train_params: dict[str, str | int | float | None] = { \n",
    "            \"data\": datayml_path,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"device\": self.device,\n",
    "            \"batch\": self.batch,\n",
    "            \"patience\": self.patience,\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr0\": self.lr0,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"momentum\": self.momentum,\n",
    "            \"warmup_epochs\": self.warmup_epochs,\n",
    "            \"mixup\": self.mixup,\n",
    "            \"mosaic\": self.mosaic,\n",
    "            \"copy_paste\": self.copy_paste,\n",
    "        }\n",
    "\n",
    "        train_params: dict[str, str | int | float]  = {key: value for key, value in all_train_params.items() if value is not None}\n",
    "\n",
    "        logging.info(msg=f\"Training model with parameters: {train_params}\")\n",
    "        self.model.train(**train_params)\n",
    "\n",
    "\n",
    "class RoboflowDataset:\n",
    "    def __init__(self, \n",
    "                datasets_path: str, \n",
    "                api_key: str, \n",
    "                the_workspace: str, \n",
    "                project_id: str, \n",
    "                version_number: int,\n",
    "                model_format: str) -> None:\n",
    "\n",
    "        self.datasets_path = datasets_path\n",
    "        self.api_key = api_key\n",
    "        self.the_workspace = the_workspace\n",
    "        self.project_id = project_id\n",
    "        self.version_number = version_number\n",
    "        self.model_format = model_format\n",
    "        self.dataset_path = None\n",
    "\n",
    "\n",
    "    def download_dataset(self) -> None:\n",
    "        try:\n",
    "            os.chdir(path=self.datasets_path)\n",
    "            rf: Roboflow = Roboflow(api_key=self.api_key)\n",
    "            project: Project = rf.workspace(the_workspace=self.the_workspace).project(project_id=self.project_id)\n",
    "            version: Version = project.version(version_number=self.version_number)\n",
    "            dataset: Dataset = version.download(model_format=self.model_format)\n",
    "        except:\n",
    "            logging.error(msg=f\"Something went wrong downloading the dataset\")\n",
    "            ValueError('Something went wrong downloading the dataset.')\n",
    "    \n",
    "    def find_dataset_path(self) -> str | None:\n",
    "        try:\n",
    "            dataset_path: str = DirectoryUtil.find_downloaded_dataset(datasets_path=self.datasets_path,\n",
    "                                                                    project_id=self.project_id,\n",
    "                                                                    version_number=self.version_number)\n",
    "            logging.info(msg=f\"Dataset is: {dataset_path}\")\n",
    "            self.dataset_path = dataset_path\n",
    "            return dataset_path\n",
    "        except:\n",
    "            logging.error(msg=f\"Something went wrong finding the dataset\")\n",
    "            ValueError('Something went wrong finding the dataset.')\n",
    "    \n",
    "    def prepare_dataset_datayml(self) -> None:\n",
    "        if self.dataset_path is None:\n",
    "            logging.error(msg=f\"Dataset path is not set. Run find_dataset_path() first.\")\n",
    "            raise ValueError(\"Dataset path is not set. Run find_dataset_path() first.\")\n",
    "\n",
    "        dataset_datayml_path: str = os.path.join(self.dataset_path, 'data.yaml')\n",
    "        # logging.info(msg=f\"dataset_datayml_path {dataset_datayml_path}\")\n",
    "\n",
    "        with open(file=dataset_datayml_path, mode='r') as file:\n",
    "            datayml_file: list[str] = file.readlines()\n",
    "\n",
    "        # logging.info(msg=f\"datayml_file {datayml_file} \")\n",
    "\n",
    "        pattern: Pattern[str] = re.compile(r\"https?://[^\\s]+\") \n",
    "\n",
    "        if(any(pattern.search(line) for line in datayml_file)):\n",
    "\n",
    "            logging.info(msg=f\"Dataset is not prepared. Preparing it...\")\n",
    "            datayml_file = datayml_file[:-4]\n",
    "            logging.info(msg=f\"Removed unneccesary content.\")\n",
    "\n",
    "            datayml_file = [line.replace(\"../train/images\", f\"{self.dataset_path}/train/images\") for line in datayml_file]\n",
    "            datayml_file = [line.replace(\"../valid/images\", f\"{self.dataset_path}/valid/images\") for line in datayml_file]\n",
    "            datayml_file = [line.replace(\"../test/images\", f\"{self.dataset_path}/test/images\") for line in datayml_file]\n",
    "\n",
    "            logging.info(msg=f\"Added correct train, valid and test images path.\")\n",
    "\n",
    "            with open(file=dataset_datayml_path,mode= 'w') as f:\n",
    "                f.writelines(datayml_file)\n",
    "\n",
    "            logging.info(msg=f\"Saved prepared file.\")\n",
    "        \n",
    "        logging.info(msg=f\"Dataset is ready to use for training.\")\n",
    "\n",
    "class Yolo:\n",
    "    def __init__(self,\n",
    "                models_dir: str,\n",
    "                yolo_model: str = \"yolov12l.pt\",\n",
    "                min_code_prediction_threshold: int = 3,\n",
    "                min_diagram_prediction_threshold: int = 3) -> None:\n",
    "\n",
    "        self.models_dir = models_dir\n",
    "        self.yolo_model = yolo_model\n",
    "        self.yolo_model_path = None\n",
    "\n",
    "        yolo_path: str = os.path.join(models_dir, \"yolov12\")\n",
    "        if os.path.isdir(s=yolo_path):\n",
    "            logging.info(msg=\"Yolo was found. Initializing.\")\n",
    "            self.yolo_model_path = f\"{self.models_dir}/yolov12/{self.yolo_model}\"\n",
    "        else:\n",
    "            logging.info(msg=\"Yolo was not found, dowloading it...\")\n",
    "            os.chdir(path=self.models_dir)\n",
    "            repo_url: str = f\"https://github.com/sunsmarterjie/yolov12\"\n",
    "\n",
    "            try:\n",
    "                logging.info(msg=\"Downloading...\")\n",
    "                subprocess.run([\"git\", \"clone\", repo_url, yolo_path], check=True)\n",
    "                logging.info(msg=\"Downloaded completed...\")\n",
    "            except subprocess.CalledProcessError:\n",
    "                logging.error(msg=\"Cloud not download yolov12 from git. Check if git is installed.\")\n",
    "                RuntimeError(\"Cloud not download yolov12 from git. Check if git is installed.\")\n",
    "            \n",
    "            commands: list[list[str]] = [\n",
    "                [\"pip\", \"install\", \"roboflow\", \"supervision\", \"flash-attn\", \"--upgrade\", \"-q\"],\n",
    "                [\"pip\", \"install\", \"-r\", \"requirements.txt\"],\n",
    "                [\"pip\", \"install\", \"-e\", \".\"],\n",
    "                [\"pip\", \"install\", \"--upgrade\", \"flash-attn\"],\n",
    "                [\"wget\", f\"https://github.com/sunsmarterjie/yolov12/releases/download/v1.0/{yolo_model}\"]\n",
    "            ]\n",
    "\n",
    "            os.chdir(path=yolo_path)\n",
    "            for command in commands:\n",
    "                try:\n",
    "                    logging.info(msg=f\"Executing {' '.join(command)}\")\n",
    "                    subprocess.run(command, check=True)\n",
    "                    logging.info(msg=\"Command executed successfully\")\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    logging.info(msg=f\"Error while executing {command}. Details: {e}\")\n",
    "\n",
    "        self.yolo_model_path = f\"{self.models_dir}/yolov12/{self.yolo_model}\"\n",
    "        device: Literal['cuda', 'cpu'] = \"cuda\" if is_available() else \"cpu\"\n",
    "        if device == 'cuda':\n",
    "            logging.info(msg=\"GPU detected. Using it.\")\n",
    "        elif device == 'cpu':\n",
    "            logging.info(msg=\"GPU not detected. Swichting to CPU.\")\n",
    "        \n",
    "        self.code_model = None\n",
    "        self.diagram_model = None\n",
    "        self.min_code_prediction_threshold = min_code_prediction_threshold\n",
    "        self.min_diagram_prediction_threshold = min_diagram_prediction_threshold\n",
    "        self.valid_subjects = {\"code\", \"diagram\"}\n",
    "        self.valid_images_extensions = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
    "    \n",
    "    def clear_cache(self) -> None:\n",
    "        empty_cache()\n",
    "        logging.info(msg=\"GPU cache has been cleared.\")\n",
    "\n",
    "    def is_subject_valid(self, subject: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the given subject extension is valid.\n",
    "\n",
    "        Args:\n",
    "            subject (str): The subject (e.g., \".code\").\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the subject is valid, False otherwise.\n",
    "        \"\"\"\n",
    "        return subject.lower() in self.valid_subjects\n",
    "\n",
    "    def is_image_extension_valid(self, image_extension: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the given image extension is valid.\n",
    "\n",
    "        Args:\n",
    "            image_extension (str): The image extension (e.g., \".png\").\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the extension is valid, False otherwise.\n",
    "        \"\"\"\n",
    "        return image_extension.lower() in self.valid_images_extensions\n",
    "    \n",
    "    def format_detections_to_predictions(self, detections) -> dict[str, list[Any]]:\n",
    "        formatted_predictions: list[Any] = []\n",
    "\n",
    "        for i, (xyxy, conf, cls) in enumerate(zip(detections.xyxy, detections.confidence, detections.class_id)):\n",
    "            x_min, y_min, x_max, y_max = xyxy\n",
    "            \n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            x_center = x_min + width / 2\n",
    "            y_center = y_min + height / 2\n",
    "\n",
    "            detection_id: str = str(uuid.uuid4())\n",
    "\n",
    "            formatted_predictions.append({\n",
    "                \"x\": round(number=float(x_center),ndigits=2),\n",
    "                \"y\": round(number=float(y_center), ndigits=2),\n",
    "                \"width\": round(number=float(width), ndigits=2),\n",
    "                \"height\": round(number=float(height), ndigits=2),\n",
    "                \"confidence\": round(number=float(conf),ndigits=3),\n",
    "                \"class\": \"code_snippet\",\n",
    "                \"class_id\": int(cls),\n",
    "                \"detection_id\": detection_id\n",
    "            })\n",
    "\n",
    "        return {\"predictions\": formatted_predictions}\n",
    "\n",
    "    def set_code_model(self, path: str) -> None:\n",
    "        self.code_model = YOLO(model=path)\n",
    "\n",
    "    def set_diagram_model(self, path: str) -> None:\n",
    "        self.diagram_model = YOLO(model=path)\n",
    "\n",
    "    def predict_code(self, image: Path) -> list[Any]:\n",
    "        if self.code_model is None:\n",
    "            raise ValueError(\"Code Model is not set. Run train_model(subject='code') or set_code_model(path='path/to/model') first.\")\n",
    "\n",
    "        raw_code_detection_results = self.code_model(source=image, verbose=False)[0]\n",
    "        code_detection_resutls: Detections = Detections.from_ultralytics(ultralytics_results=raw_code_detection_results).with_nms()\n",
    "        code_predictions: dict[str, list[Any]] = self.format_detections_to_predictions(detections=code_detection_resutls)\n",
    "        code_predictions[\"predictions\"] = self.sort_predictions_by_y(predictions=code_predictions[\"predictions\"])\n",
    "\n",
    "        return code_predictions[\"predictions\"]\n",
    "\n",
    "    def predict_diagram(self, image: Path) -> list[Any]:\n",
    "        if self.diagram_model is None:\n",
    "            raise ValueError(\"Diagram Model is not set. Run train_model(subject='diagram') or set_diagram_model(path='path/to/model') first.\")\n",
    "\n",
    "        raw_diagram_detection_results = self.diagram_model(source=image, verbose=False)[0]\n",
    "        diagram_detection_resutls: Detections = Detections.from_ultralytics(ultralytics_results=raw_diagram_detection_results).with_nms()\n",
    "        diagram_predictions: dict[str, list[Any]] = self.format_detections_to_predictions(detections=diagram_detection_resutls)\n",
    "        diagram_predictions[\"predictions\"] = self.sort_predictions_by_y(predictions=diagram_predictions[\"predictions\"])\n",
    "\n",
    "        return diagram_predictions[\"predictions\"]\n",
    "\n",
    "    def sort_predictions_by_x(self, predictions: list[Any]) -> list[Any]:\n",
    "        return sorted(predictions, key=lambda obj: obj[\"x\"])\n",
    "\n",
    "    def sort_predictions_by_y(self, predictions: list[Any]) -> list[Any]:\n",
    "        return sorted(predictions, key=lambda obj: obj[\"y\"])\n",
    "        \n",
    "    def filter_images_with_code(self, images_path: Path) -> list[Path]:\n",
    "        if self.code_model is None:\n",
    "            raise ValueError(\"Code Model is not set. Run train_model(subject='code') or set_code_model(path='path/to/model') first.\")\n",
    "\n",
    "        valid_code_images_path: list[Path] = []\n",
    "\n",
    "        all_images_paths: list[Path] = [file for file in images_path.iterdir() if self.is_image_extension_valid(image_extension=file.suffix)]\n",
    "\n",
    "        for image_path in all_images_paths:\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                logging.error(msg=f\"Image: '{image_path.name}' could not be loaded. Skipping to the next image.\")\n",
    "                continue\n",
    "                \n",
    "            raw_code_detection_results = self.code_model(source=image, verbose=False)[0]\n",
    "            code_detection_resutls: Detections = Detections.from_ultralytics(ultralytics_results=raw_code_detection_results).with_nms()\n",
    "            code_predictions: dict[str, list[Any]] = self.format_detections_to_predictions(detections=code_detection_resutls)\n",
    "\n",
    "            if len(code_predictions[\"predictions\"]) > self.min_code_prediction_threshold:\n",
    "                valid_code_images_path.append(image_path)\n",
    "\n",
    "        return valid_code_images_path\n",
    "\n",
    "    def filter_images_with_diagrams(self, images_path: Path) -> list[Path]:\n",
    "        if self.diagram_model is None:\n",
    "            raise ValueError(\"Diagram Model is not set. Run train_model(subject='code') or set_diagram_model(path='path/to/model') first.\")\n",
    "\n",
    "        valid_diagram_images_path: list[Path] = []\n",
    "\n",
    "        all_images_paths: list[Path] = [file for file in images_path.iterdir() if self.is_image_extension_valid(image_extension=file.suffix)]\n",
    "\n",
    "        for image_path in all_images_paths:\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                logging.error(msg=f\"Image: '{image_path.name}' could not be loaded. Skipping to the next image.\")\n",
    "                continue\n",
    "                \n",
    "            raw_diagram_detection_results = self.diagram_model(source=image, verbose=False)[0]\n",
    "            diagram_detection_resutls: Detections  = Detections.from_ultralytics(ultralytics_results=raw_diagram_detection_results).with_nms()\n",
    "            diagram_predictions: dict[str, list[Any]] = self.format_detections_to_predictions(detections=diagram_detection_resutls)\n",
    "\n",
    "            if len(diagram_predictions[\"predictions\"]) > self.min_diagram_prediction_threshold:\n",
    "                valid_diagram_images_path.append(image_path)\n",
    "\n",
    "        return valid_diagram_images_path\n",
    "\n",
    "    def save_filter_images(self, images: list[Path], output_dir_path: Path) -> None:\n",
    "        for image in images:\n",
    "            shutil.copy(src=image, dst=output_dir_path)\n",
    "        \n",
    "        logging.info(msg=f\"Filtered images saved to: {output_dir_path}\")\n",
    "\n",
    "    \n",
    "    def filter_images_with(self, subject: str, images_path: Path, output_dir_path: Path) -> list[Path]:\n",
    "        if not self.is_subject_valid(subject):\n",
    "            logging.error(msg=f\"Subject is not valid. Only 'code' and 'diagram' are valid.\")\n",
    "            raise ValueError(\"Subject is not valid. Only 'code' and 'diagram' are valid.\")\n",
    "\n",
    "        match subject:\n",
    "            case \"code\":\n",
    "                valid_code_images_path: list[Path] = self.filter_images_with_code(images_path)\n",
    "                self.save_filter_images(images=valid_code_images_path, output_dir_path=output_dir_path)\n",
    "                return valid_code_images_path\n",
    "            case \"diagram\":\n",
    "                valid_diagram_images_path: list[Path] = self.filter_images_with_diagrams(images_path)\n",
    "                self.save_filter_images(images=valid_diagram_images_path, output_dir_path=output_dir_path)\n",
    "                return valid_diagram_images_path\n",
    "            case _:\n",
    "                return []\n",
    "\n",
    "    def train_code_model_with_dataset(self, roboflowDataset: RoboflowDataset) -> None:\n",
    "        roboflowDataset.download_dataset()\n",
    "        roboflowDataset.find_dataset_path()\n",
    "        if(roboflowDataset.dataset_path is None):\n",
    "            logging.error(msg=\"Dataset path is not set. Run find_dataset_path() or check your params.\")\n",
    "            raise ValueError(\"Dataset path is not set. Run find_dataset_path() or check your params.\")\n",
    "            \n",
    "        if not self.is_subject_valid(subject=\"code\"):\n",
    "            logging.error(msg=\"Subject is not valid. Only 'code' is valid.\")\n",
    "            raise ValueError(\"Subject is not valid. Only 'code' is valid.\")\n",
    "\n",
    "        if self.yolo_model_path is None:\n",
    "            logging.error(msg=\"Yolo model path is not set. Check if the model is downloaded.\")\n",
    "            raise ValueError(\"Yolo model path is not set. Check if the model is downloaded.\")\n",
    "\n",
    "        roboflowDataset.prepare_dataset_datayml()\n",
    "\n",
    "        logging.info(msg=\"Training code model with dataset...\")\n",
    "        model: Model = Model(model=YOLO(model=self.yolo_model_path), data=roboflowDataset.dataset_path, epochs=300, device='cuda', batch=14, imgsz=640, optimizer=\"AdamW\")\n",
    "        model.train()\n",
    "\n",
    "    def train_diagram_model_with_dataset(self, roboflowDataset: RoboflowDataset) -> None:\n",
    "        roboflowDataset.download_dataset()\n",
    "        roboflowDataset.find_dataset_path()\n",
    "        if(roboflowDataset.dataset_path is None):\n",
    "            logging.error(msg=\"Dataset path is not set. Run find_dataset_path() or check your params.\")\n",
    "            raise ValueError(\"Dataset path is not set. Run find_dataset_path() or check your params.\")\n",
    "\n",
    "        if not self.is_subject_valid(subject=\"diagram\"):\n",
    "            logging.error(msg=\"Subject is not valid. Only 'diagram' is valid.\")\n",
    "            raise ValueError(\"Subject is not valid. Only 'diagram' is valid.\")\n",
    "\n",
    "        if self.yolo_model_path is None:\n",
    "            logging.error(msg=\"Yolo model path is not set. Check if the model is downloaded.\")\n",
    "            raise ValueError(\"Yolo model path is not set. Check if the model is downloaded.\")\n",
    "\n",
    "        roboflowDataset.prepare_dataset_datayml()\n",
    "\n",
    "        logging.info(msg=\"Training diagram model with dataset...\")\n",
    "\n",
    "        model: Model = Model(model=YOLO(model=self.yolo_model_path), data=roboflowDataset.dataset_path, epochs=300, device='cuda', batch=14, imgsz=640, optimizer=\"AdamW\")\n",
    "        model.train()\n",
    "\n",
    "    def train_model_with_and_dataset(self, subject: str, roboflowDataset: RoboflowDataset) -> None: \n",
    "        if not self.is_subject_valid(subject):\n",
    "            logging.error(msg=f\"Subject is not valid. Only 'code' and 'diagram' are valid.\")\n",
    "            raise ValueError(\"Subject is not valid. Only 'code' and 'diagram' are valid.\")\n",
    "\n",
    "        match subject:\n",
    "            case \"code\":\n",
    "                self.train_code_model_with_dataset(roboflowDataset=roboflowDataset)\n",
    "            case \"diagram\":\n",
    "                self.train_diagram_model_with_dataset(roboflowDataset=roboflowDataset)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_train_metrics(models_dir: str, train: str) -> Tuple[Image, Image, pd.DataFrame]:\n",
    "        # confusion_matrix_path: str = f\"{models_dir}/yolov12/runs/detect/{train}/confusion_matrix.png\" \n",
    "        # train_results_image_path: str = f\"{models_dir}/yolov12/runs/detect/{train}/results.png\"\n",
    "        # train_results_csv_path: str = f\"{models_dir}/yolov12/runs/detect/{train}/results.csv\"\n",
    "\n",
    "        confusion_matrix_path: str = f\"/kaggle/working/datasets/runs/detect/{train}/confusion_matrix.png\" \n",
    "        train_results_image_path: str = f\"/kaggle/working/datasets/runs/detect/{train}/results.png\"\n",
    "        train_results_csv_path: str = f\"/kaggle/working/datasets/runs/detect/{train}/results.csv\"\n",
    "\n",
    "        confusion_matrix_img = Image(filename=confusion_matrix_path, width=800)\n",
    "        train_results_img = Image(filename=train_results_image_path, width=800)\n",
    "        train_results_df = pd.read_csv(train_results_csv_path)\n",
    "        \n",
    "        return confusion_matrix_img, train_results_img, train_results_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR: str = '/teamspace/studios/this_studio/models'\n",
    "DATASET_DIR: str = '/teamspace/studios/this_studio/datasets'\n",
    "IMAGES_DIR: str = '/teamspace/studios/this_studio/detects_scenes'\n",
    "VALID_IAMGES_DIR = '/teamspace/studios/this_studio/valid_detects_scenes'\n",
    "API_KEY: str = os.environ[\"ROBOFLOW_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 19:32:38,298 - INFO - Directory already exists: /teamspace/studios/this_studio/models\n",
      "2025-03-23 19:32:38,301 - INFO - Yolo was found. Initializing.\n",
      "2025-03-23 19:32:38,302 - INFO - GPU not detected. Swichting to CPU.\n"
     ]
    }
   ],
   "source": [
    "models_dir: str = DirectoryUtil.ensure_directory(path=MODELS_DIR)\n",
    "\n",
    "yolov12: Yolo = Yolo(models_dir=models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path: str = DirectoryUtil.ensure_directory(path=DATASET_DIR)\n",
    "api_key: str = API_KEY\n",
    "the_workspace: str = 'bot-interactivo-tesis'\n",
    "project_id: str = 'code-snippet-detection'\n",
    "version_number: int = 22\n",
    "model_format: str = 'yolov12'\n",
    "\n",
    "codeRoboflowDataset: RoboflowDataset = RoboflowDataset(datasets_path=datasets_path,\n",
    "                                                        api_key=api_key,\n",
    "                                                        the_workspace=the_workspace,\n",
    "                                                        project_id=project_id,\n",
    "                                                        version_number=version_number,\n",
    "                                                        model_format=model_format)\n",
    "\n",
    "\n",
    "yolov12.train_code_model_with_dataset(roboflowDataset=codeRoboflowDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 19:32:47,858 - INFO - Directory already exists: /teamspace/studios/this_studio/detects_scenes\n"
     ]
    }
   ],
   "source": [
    "images_dir: str = DirectoryUtil.ensure_directory(path=IMAGES_DIR)\n",
    "subject: str = \"code\"\n",
    "images_path: Path = Path(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov12.set_code_model(path=\"/teamspace/studios/this_studio/models/yolov12/runs/detect/train7/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov12.filter_images_with(subject=subject, images_path=images_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
