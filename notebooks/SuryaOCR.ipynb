{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from numpy import ndarray\n",
    "from typing import List, Tuple, Any\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from surya.recognition import OCRResult, RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor\n",
    "\n",
    "class SuryaOCR:\n",
    "    def __init__(self)-> None:\n",
    "        os.environ[\"RECOGNITION_BATCH_SIZE\"] = \"512\"\n",
    "        \n",
    "        self.detection_predictor = DetectionPredictor()\n",
    "        self.recognition_predictor = RecognitionPredictor()\n",
    "        self.langs = ['es', 'en']\n",
    "\n",
    "    def get_predictions(self, image: Image.Image)-> List[OCRResult]:\n",
    "        return self.recognition_predictor(images=[image], langs=[self.langs], det_predictor=self.detection_predictor)\n",
    "\n",
    "    def get_text_from_predictions(self, predictions: List[OCRResult]) -> str:\n",
    "        if not predictions:\n",
    "            raise ValueError('Predictions are required')\n",
    "        if not predictions[0].text_lines:\n",
    "            return 'No text detected.'\n",
    "        return predictions[0].text_lines[0].text\n",
    "\n",
    "    def get_bouding_boxes_from_predictions(self, predictions: List[OCRResult])-> List[float]:\n",
    "        if not predictions:\n",
    "            raise ValueError('Predictions are required')\n",
    "        if not predictions[0].text_lines:\n",
    "            return [0, 0, 0, 0]\n",
    "        return predictions[0].text_lines[0].bbox\n",
    "\n",
    "    def get_confidence_from_predictions(self, predictions: List[OCRResult])-> float:\n",
    "        if not predictions:\n",
    "            raise ValueError('Predictions are required')\n",
    "        if not predictions[0].text_lines:\n",
    "            return 0\n",
    "        confidence: float | None = predictions[0].text_lines[0].confidence\n",
    "        return confidence if confidence is not None else 0\n",
    "\n",
    "    def show_image_with_bounding_boxes(self, image_path: str, bounding_boxes: List[float], text: str = \"Image with boundings\")-> None:\n",
    "        if not image_path:\n",
    "            raise ValueError('Image is required')\n",
    "        if not bounding_boxes:\n",
    "            raise ValueError('Bounding boxes are required')\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, bounding_boxes)\n",
    "\n",
    "        cv2.rectangle(img=image, pt1=(x1, y1), pt2=(x2, y2), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        plt.imshow(X=cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(label=text)\n",
    "        plt.show()\n",
    "\n",
    "    def cropped_image(self, image_path: str, bounding_boxes: List[float], showImage: bool):\n",
    "        if not image_path:\n",
    "            raise ValueError('Image is required')\n",
    "        if not bounding_boxes:\n",
    "            raise ValueError('Bounding boxes are required')\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, bounding_boxes)\n",
    "        cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "        if showImage:\n",
    "            self.show_image_with_bounding_boxes(image_path=image_path, bounding_boxes=bounding_boxes, text='Cropped Image')\n",
    "\n",
    "        return cropped_image\n",
    "\n",
    "    def save_cropped_image(self, image: ndarray, output_dir: Path, name: str)-> None: \n",
    "        if image.size == 0:\n",
    "            raise ValueError('Image is required')\n",
    "        if not output_dir:\n",
    "            raise ValueError('Output directory is required')\n",
    "\n",
    "        os.chdir(path=output_dir)\n",
    "        cv2.imwrite(name, image)\n",
    "\n",
    "    def predict(self, image_path: str, show_result: bool = False)-> Tuple[str, List[float], float]:\n",
    "        if not image_path:\n",
    "            raise ValueError('Image is required')\n",
    "\n",
    "        image: Image.Image = Image.open(fp=image_path)\n",
    "        predictions: List[OCRResult] = self.get_predictions(image=image)\n",
    "        extracted_text: str = self.get_text_from_predictions(predictions=predictions)\n",
    "        bounding_boxes: List[float] = self.get_bouding_boxes_from_predictions(predictions=predictions)\n",
    "        confidence: float = self.get_confidence_from_predictions(predictions=predictions)\n",
    "\n",
    "        if show_result:\n",
    "            self.show_image_with_bounding_boxes(image_path=image_path, bounding_boxes=bounding_boxes, text=extracted_text)\n",
    "\n",
    "        return extracted_text, bounding_boxes, confidence\n",
    "\n",
    "    def cropped_image_from_predictions(self, image_path: str, predictions: dict, show_image: bool = False, show_text: bool = False) -> ndarray:\n",
    "        if not image_path:\n",
    "            raise ValueError('Image is required')\n",
    "        if not predictions:\n",
    "            raise ValueError('Predictions are required')\n",
    "\n",
    "        image: ndarray = cv2.imread(image_path)\n",
    "\n",
    "        x_center: Any = predictions[\"x\"]\n",
    "        y_center: Any = predictions[\"y\"]\n",
    "        w: Any = predictions[\"width\"]\n",
    "        h: Any = predictions[\"height\"]\n",
    "\n",
    "        x1: int = int(x_center - w/2)\n",
    "        y1: int = int(y_center - h/2)\n",
    "        x2: int = int(x_center + w/2)\n",
    "        y2: int = int(y_center + h/2)\n",
    "\n",
    "        x1 = max(0, x1)\n",
    "        y1 = max(0, y1)\n",
    "        x2 = min(image.shape[1], x2)\n",
    "        y2 = min(image.shape[0], y2)\n",
    "\n",
    "        scale_factor = 2\n",
    "\n",
    "        cropped_image: ndarray = image[y1:y2, x1:x2]\n",
    "        # rescaled_image = cv2.resize(\n",
    "        #     cropped_image,\n",
    "        #     None,\n",
    "        #     fx=scale_factor,\n",
    "        #     fy=scale_factor,\n",
    "        #     interpolation=cv2.INTER_LANCZOS4\n",
    "        # )\n",
    "        gray_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "        channles_image = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        if show_text:\n",
    "            cv2.imwrite(\"tmp_cropped_image.jpg\", channles_image)\n",
    "            text, _, _ = self.predict(image_path=\"tmp_cropped_image.jpg\")\n",
    "            Path(\"tmp_cropped_image.jpg\").unlink()\n",
    "\n",
    "        if show_image:\n",
    "            plt.imshow(X=channles_image)\n",
    "            if show_text:\n",
    "                plt.title(label=text)\n",
    "            else:\n",
    "                plt.title(label=\"Cropped Image\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "        return cropped_image\n",
    "    \n",
    "    def get_image_name_from_path(self, image_path: str)-> str:\n",
    "        if not image_path:\n",
    "            raise ValueError('Image is required')\n",
    "\n",
    "        return Path(image_path).stem\n",
    "    \n",
    "    def predict_and_save_cropped_image(self, image_path: str, predictions: list[Any], output_dir: Path)-> list[Any]:\n",
    "        if image_path is None:\n",
    "            raise ValueError('Image is required')\n",
    "        if not predictions:\n",
    "            raise ValueError('Predictions are required')\n",
    "        if not output_dir:\n",
    "            raise ValueError('Output directory is required')\n",
    "\n",
    "        image_name: str = self.get_image_name_from_path(image_path=image_path)\n",
    "\n",
    "        for index, prediction in enumerate(predictions):\n",
    "            try:\n",
    "                cropped_image: ndarray = self.cropped_image_from_predictions(image_path=image_path, predictions=prediction, show_image=True, show_text=True)\n",
    "                self.save_cropped_image(image=cropped_image, output_dir=output_dir, name=f\"{image_name}_{index}.jpg\")\n",
    "                new_image_path = f\"{output_dir}/{image_name}_{index}.jpg\"\n",
    "                text, _, _ = self.predict(image_path=new_image_path)\n",
    "                prediction[\"text\"] = text\n",
    "            except Exception as e:\n",
    "                logging.error(msg=f\"There was an error adding this prediction: {e}\")\n",
    "                continue\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def natural_key(self, filename: str):\n",
    "        return [int(text) if text.isdigit() else text.lower() for text in re.split('(\\d+)', filename)]\n",
    "\n",
    "    def extract_text_and_y(self, predictions: list[Any]) -> list[dict]:\n",
    "        result = []\n",
    "        for prediction in predictions:\n",
    "            if \"text\" in prediction and \"y\" in prediction:\n",
    "                text = prediction[\"text\"].strip()\n",
    "                if text:  # Se incluye solo si el texto no está vacío\n",
    "                    result.append({\"text\": text, \"y\": prediction[\"y\"]})\n",
    "        return result\n",
    "\n",
    "    def predict_and_save_from_dir(self, input_dir: Path, output_dir: Path, yolov12: Yolo) -> list[dict]:\n",
    "        if not input_dir:\n",
    "            raise ValueError('Input directory is required')\n",
    "        if not output_dir:\n",
    "            raise ValueError('Output directory is required')\n",
    "    \n",
    "        results = []\n",
    "    \n",
    "        for image_path in sorted(input_dir.glob(\"*.png\"), key=lambda p: self.natural_key(p.name)):\n",
    "            logging.info(msg=f\"{image_path}\")\n",
    "            print(f\"{image_path}\")\n",
    "            \n",
    "            predictions: list[Any] = yolov12.predict_code(image=image_path)\n",
    "            cropped_predictions = self.predict_and_save_cropped_image(\n",
    "                image_path=str(image_path),\n",
    "                predictions=predictions,\n",
    "                output_dir=output_dir\n",
    "            )\n",
    "\n",
    "            filtered_predictions = self.extract_text_and_y(predictions=predictions)\n",
    "            \n",
    "            results.append({\n",
    "                \"file_name\": str(image_path),\n",
    "                \"predictions\": filtered_predictions\n",
    "            })\n",
    "    \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded detection model s3://text_detection/2025_02_28 on device cpu with dtype torch.float32\n",
      "Loaded recognition model s3://text_recognition/2025_02_18 on device cpu with dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "suryaOCR: SuryaOCR = SuryaOCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image: str = \"/kaggle/working/detects_valid_scenes/test_01-Scene-005-02.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path: Path = Path(image)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
